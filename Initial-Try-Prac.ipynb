{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nairomi\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "import base64\n",
    "import matplotlib \n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import math\n",
    "import re\n",
    "import pymysql as db\n",
    "import os\n",
    "#import cv2\n",
    "import sklearn\n",
    "import datetime\n",
    "#from matplotlib import pyplot as plt\n",
    "#from sshtunnel import SSHTunnelForwarder\n",
    "from sklearn import model_selection, svm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, average_precision_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "#from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "#from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "import time\n",
    "\n",
    "from pyglmnet import GLM\n",
    "from catboost import CatBoostRegressor\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "#from mlxtend.classifier import StackingClassifier\n",
    "\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "\n",
    "\n",
    "#For Seaborn\n",
    "import seaborn as sns\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('matplotlib', 'inline')\n",
    "from matplotlib.pylab import rcParams\n",
    "rcParams['figure.figsize'] = 30,10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "#For Arima\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "#For NLP\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "import re\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,TfidfTransformer\n",
    "\n",
    "#For Bayesian Optimization\n",
    "#import bayes_opt\n",
    "#from bayes_opt import BayesianOptimization\n",
    "\n",
    "\n",
    "#Dask Framework\n",
    "import dask.dataframe as dd\n",
    "\n",
    "#For View\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(631761, 54)\n"
     ]
    }
   ],
   "source": [
    "path='C:/Users/Nairomi/Documents/GitHub/Earthquake-Damage-Grade-Prediction/Data/'\n",
    "mega_data=pd.read_csv(path+\"mega_data.csv\",sep=',',encoding=\"utf-8\",error_bad_lines=False,low_memory = False)\n",
    "print(mega_data.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#### Details of the files are as follows: \n",
    "\n",
    "#### train.csv : \n",
    "\n",
    "|Varaible| Descrition|\n",
    "|--------|-----------|\n",
    "|area_assesed|Indicates the nature of the damage assessment in terms of the areas of the building that were assessed|\n",
    "|building_id|A unique ID that identifies every individual building|\n",
    "|damage_grade|Damage grade assigned to the building after assessment (Target Variable)|\n",
    "|district_id|District where the building is located|\n",
    "|has_geotechnical_risk|Indicates if building has geotechnical risks|\n",
    "|has_geotechnical_risk_fault_crack|Indicates if building has geotechnical risks related to fault cracking|\n",
    "|has_geotechnical_risk_flood|Indicates if building has geotechnical risks related to flood|\n",
    "|has_geotechnical_risk_land_settlement|Indicates if building has geotechnical risks related to land settlement|\n",
    "|has_geotechnical_risk_landslide|Indicates if building has geotechnical risks related to landslide|\n",
    "|has_geotechnical_risk_liquefaction|Indicates if building has geotechnical risks related to liquefaction|\n",
    "|has_geotechnical_risk_other|Indicates if building has any other  geotechnical risks|\n",
    "|has_geotechnical_risk_rock_fall|Indicates if building has geotechnical risks related to rock fall|\n",
    "|has_repair_started|Indicates if the repair work had started|\n",
    "|vdcmun_id|Municipality where the building is located|\n",
    "\n",
    "#### Building_Ownership_Use.csv: \n",
    "\n",
    "|Varaible|Description|\n",
    "|--------|-----------|\n",
    "|building_id|A unique ID that identifies every individual building|\n",
    "|district_id|District where the building is located|\n",
    "|vdcmun_id|Municipality where the building is located|\n",
    "|ward_id|Ward Number in which the building is located|\n",
    "|legal_ownership_status|Legal ownership status of the land in which the building was built|\n",
    "|count_families|Number of families in the building|\n",
    "|has_secondary_use|indicates if the building is used for any secondary purpose|\n",
    "|has_secondary_use_agriculture|indicates if the building is secondarily used for agricultural purpose|\n",
    "|has_secondary_use_hotel|indicates if the building is secondarily used as hotel|\n",
    "|has_secondary_use_rental|indicates if the building is secondarily used for rental purpose|\n",
    "|has_secondary_use_institution|indicates if the building is secondarily used for institutional purpose|\n",
    "|has_secondary_use_school|indicates if the building is secondarily used as school|\n",
    "|has_secondary_use_industry|indicates if the building is secondarily used for industrial purpose|\n",
    "|has_secondary_use_health_post|indicates if the building is secondarily used as health post|\n",
    "|has_secondary_use_gov_office|indicates if the building is secondarily used as government office|\n",
    "|has_secondary_use_use_police|indicates if the building is secondarily used as police station|\n",
    "|has_secondary_use_other|indicates if the building is secondarily used for other purpose|\n",
    "\n",
    "\n",
    "#### Building_Structure.csv\n",
    "\n",
    "|Variable|Description|\n",
    "|--------|-----------|\n",
    "|building_id|A unique ID that identifies every individual building|\n",
    "|district_id|District where the building is located|\n",
    "|vdcmun_id|Municipality where the building is located|\n",
    "|ward_id|Ward Number in which the building is located|\n",
    "|count_floors_pre_eq|Number of floors that the building had before the earthquake|\n",
    "|count_floors_post_eq|Number of floors that the building had after the earthquake|\n",
    "|age_building|Age of the building (in years)|\n",
    "|plinth_area_sq_ft|Plinth area of the building (in square feet)|\n",
    "|height_ft_pre_eq|Height of the building before the earthquake (in feet)|\n",
    "|height_ft_post_eq|Height of the building after the earthquake (in feet)|\n",
    "|land_surface_condition|Surface condition of the land in which the building is built\t|\n",
    "|foundation_type|Type of foundation used in the building|\n",
    "|roof_type|Type of roof used in the building|\n",
    "|ground_floor_type|Ground floor type|\n",
    "|other_floor_type|Type of construction used in other floors (except ground floor and roof)|\n",
    "|position|Position of the building|\n",
    "|plan_configuration|Building plan configuration|\n",
    "|has_superstructure_adobe_mud|indicates if the superstructure of the building is made of Adobe/Mud|\n",
    "|has_superstructure_mud_mortar_stone|indicates if the superstructure of the building is made of Mud Mortar - Stone|\n",
    "|has_superstructure_stone_flag| indicates if the superstructure of the building is made of Stone|\n",
    "|has_superstructure_mud_mortar_brick|indicates if the superstructure of the building is made of Cement Mortar - Stone|\n",
    "|has_superstructure_cement_mortar_brick|indicates if the superstructure of the building is made of Mud Mortar - Brick|\n",
    "|has_superstructure_timber|indicates if the superstructure of the building is made of Timber|\n",
    "|has_superstructure_bamboo|indicates if the superstructure of the building is made of Bamboo|\n",
    "|has_superstructure_rc_non_engineered|indicates if the superstructure of the building is made of RC (Non Engineered)|\n",
    "|has_superstructure_rc_engineered|indicates if the superstructure of the building is made of RC (Engineered)|\n",
    "|has_superstructure_other| indicates if the superstructure of the building is made of any other material|\n",
    "|condition_post_eq|Actual contition of the building after the earthquake|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features on the Basis of District Level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  has_ features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_features=['has_geotechnical_risk_fault_crack','has_geotechnical_risk_flood','has_geotechnical_risk_land_settlement',\n",
    "       'has_geotechnical_risk_landslide', 'has_geotechnical_risk_liquefaction','has_geotechnical_risk_other', \n",
    "        'has_geotechnical_risk_rock_fall','has_repair_started','has_secondary_use', 'has_secondary_use_agriculture',\n",
    "       'has_secondary_use_hotel', 'has_secondary_use_rental','has_secondary_use_institution', 'has_secondary_use_school',\n",
    "       'has_secondary_use_industry', 'has_secondary_use_health_post','has_secondary_use_gov_office',\n",
    "        'has_secondary_use_use_police','has_secondary_use_other','has_superstructure_adobe_mud',\n",
    "       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag','has_superstructure_cement_mortar_stone',\n",
    "       'has_superstructure_mud_mortar_brick','has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
    "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered','has_superstructure_rc_engineered',\n",
    "        'has_superstructure_other']\n",
    "district_list=mega_data.district_id.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation has_features_count Columns\n",
    "for i in has_features:\n",
    "    mega_data[i+'_district_count']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in has_features:\n",
    "    for dist in district_list:\n",
    "        temp_new = pd.DataFrame()\n",
    "        temp_new = mega_data.loc[mega_data.district_id == dist, :]\n",
    "        temp_new = temp_new.reset_index()\n",
    "        temp_new.drop('index', axis=1, inplace=True)\n",
    "        \n",
    "        has_obj=temp_new[temp_new[i]==1]\n",
    "        value=len(has_obj)\n",
    "        \n",
    "        mega_data[i+'_district_count']=np.where(mega_data['district_id']==dist, value, mega_data[i+'_district_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RATIO \n",
    "#### [No of Records Having 1] / [Total Number of Records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation has_features_ratio Columns\n",
    "for i in has_features:\n",
    "    mega_data[i+'_district_ratio']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in has_features:\n",
    "    for dist in district_list:\n",
    "        temp_new = pd.DataFrame()\n",
    "        temp_new = mega_data.loc[mega_data.district_id == dist, :]\n",
    "        temp_new = temp_new.reset_index()\n",
    "        temp_new.drop('index', axis=1, inplace=True)\n",
    "        \n",
    "        has_obj=temp_new[temp_new[i]==1]\n",
    "        value=len(has_obj)/len(temp_new)\n",
    "        \n",
    "        mega_data[i+'_district_ratio']=np.where(mega_data['district_id']==dist, value, mega_data[i+'_district_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVERAGE RATIO\n",
    "#### { [Number of Records Having 0] / [Total Number of Records] } / { [Number of Records Having 1] / [Total Number of Records] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation has_features_ratio Columns\n",
    "for i in has_features:\n",
    "    mega_data[i+'_district_average_ratio']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in has_features:\n",
    "    for dist in district_list:\n",
    "        temp_new = pd.DataFrame()\n",
    "        temp_new = mega_data.loc[mega_data.district_id == dist, :]\n",
    "        temp_new = temp_new.reset_index()\n",
    "        temp_new.drop('index', axis=1, inplace=True)\n",
    "        \n",
    "        has_obj=temp_new[temp_new[i]==1]\n",
    "        nos_obj=temp_new[temp_new[i]==0]\n",
    "        value=(len(has_obj)/len(temp_new))/(len(nos_obj)/len(temp_new))\n",
    "        \n",
    "        mega_data[i+'_district_average_ratio']=np.where(mega_data['district_id']==dist, value, mega_data[i+'_district_average_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features on the Basis of Municipal Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_features=['has_geotechnical_risk_fault_crack','has_geotechnical_risk_flood','has_geotechnical_risk_land_settlement',\n",
    "       'has_geotechnical_risk_landslide', 'has_geotechnical_risk_liquefaction','has_geotechnical_risk_other', \n",
    "        'has_geotechnical_risk_rock_fall','has_repair_started','has_secondary_use', 'has_secondary_use_agriculture',\n",
    "       'has_secondary_use_hotel', 'has_secondary_use_rental','has_secondary_use_institution', 'has_secondary_use_school',\n",
    "       'has_secondary_use_industry', 'has_secondary_use_health_post','has_secondary_use_gov_office',\n",
    "        'has_secondary_use_use_police','has_secondary_use_other','has_superstructure_adobe_mud',\n",
    "       'has_superstructure_mud_mortar_stone', 'has_superstructure_stone_flag','has_superstructure_cement_mortar_stone',\n",
    "       'has_superstructure_mud_mortar_brick','has_superstructure_cement_mortar_brick', 'has_superstructure_timber',\n",
    "       'has_superstructure_bamboo', 'has_superstructure_rc_non_engineered','has_superstructure_rc_engineered',\n",
    "        'has_superstructure_other']\n",
    "municipal_list=mega_data.vdcmun_id.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation has_features_count Columns\n",
    "for i in has_features:\n",
    "    mega_data[i+'_municipal_count']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in has_features:\n",
    "    for mun in municipal_list:\n",
    "        temp_new = pd.DataFrame()\n",
    "        temp_new = mega_data.loc[mega_data.vdcmun_id == mun, :]\n",
    "        temp_new = temp_new.reset_index()\n",
    "        temp_new.drop('index', axis=1, inplace=True)\n",
    "        \n",
    "        has_obj=temp_new[temp_new[i]==1]\n",
    "        value=len(has_obj)\n",
    "        \n",
    "        mega_data[i+'_municipal_count']=np.where(mega_data['vdcmun_id']==mun, value, mega_data[i+'_municipal_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RATIO \n",
    "#### [No of Records Having 1] / [Total Number of Records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation has_features_ratio Columns\n",
    "for i in has_features:\n",
    "    mega_data[i+'_municipal_ratio']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in has_features:\n",
    "    for mun in municipal_list:\n",
    "        temp_new = pd.DataFrame()\n",
    "        temp_new = mega_data.loc[mega_data.vdcmun_id == mun, :]\n",
    "        temp_new = temp_new.reset_index()\n",
    "        temp_new.drop('index', axis=1, inplace=True)\n",
    "        \n",
    "        has_obj=temp_new[temp_new[i]==1]\n",
    "        value=len(has_obj)/len(temp_new)\n",
    "        \n",
    "        mega_data[i+'_municipal_ratio']=np.where(mega_data['vdcmun_id']==mun, value, mega_data[i+'_municipal_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVERAGE RATIO\n",
    "#### { [Number of Records Having 0] / [Total Number of Records] } / { [Number of Records Having 1] / [Total Number of Records] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creation has_features_ratio Columns\n",
    "for i in has_features:\n",
    "    mega_data[i+'_municipal_average_ratio']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in has_features:\n",
    "    for mun in municipal_list:\n",
    "        temp_new = pd.DataFrame()\n",
    "        temp_new = mega_data.loc[mega_data.vdcmun_id == mun, :]\n",
    "        temp_new = temp_new.reset_index()\n",
    "        temp_new.drop('index', axis=1, inplace=True)\n",
    "        \n",
    "        has_obj=temp_new[temp_new[i]==1]\n",
    "        nos_obj=temp_new[temp_new[i]==0]\n",
    "        if(len(nos_obj)==0):\n",
    "            value=0\n",
    "        else:\n",
    "            value=(len(has_obj)/len(temp_new))/(len(nos_obj)/len(temp_new))\n",
    "        \n",
    "        mega_data[i+'_municipal_average_ratio']=np.where(mega_data['vdcmun_id']==mun, value, mega_data[i+'_municipal_average_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVERAGE NUMBER OF FLOORS BEFORE EARTHQUAKE  DISTRICT, MUNICIPAL and WARD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List On District, Municipal and Ward Level\n",
    "district_list=mega_data.district_id.unique().tolist()\n",
    "municipal_list=mega_data.vdcmun_id.unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#District LEvel\n",
    "mega_data['avg_floors_before_quake_district']=0\n",
    "for dist in district_list:\n",
    "        temp_new = pd.DataFrame()\n",
    "        temp_new = mega_data.loc[mega_data.district_id == dist, :]\n",
    "        temp_new = temp_new.reset_index()\n",
    "        temp_new.drop('index', axis=1, inplace=True)\n",
    "        \n",
    "        number_of_floors=temp_new['count_floors_pre_eq'].sum()\n",
    "        value=number_of_floors/len(temp_new)\n",
    "        \n",
    "        mega_data['avg_floors_before_quake_district']=np.where(mega_data['district_id']==dist, value, mega_data['avg_floors_before_quake_district'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Municipal LEvel\n",
    "mega_data['avg_floors_before_quake_municipal']=0\n",
    "for mun in municipal_list:\n",
    "        temp_new = pd.DataFrame()\n",
    "        temp_new = mega_data.loc[mega_data.vdcmun_id == mun, :]\n",
    "        temp_new = temp_new.reset_index()\n",
    "        temp_new.drop('index', axis=1, inplace=True)\n",
    "        \n",
    "        number_of_floors=temp_new['count_floors_pre_eq'].sum()\n",
    "        value=number_of_floors/len(temp_new)\n",
    "        \n",
    "        mega_data['avg_floors_before_quake_municipal']=np.where(mega_data['vdcmun_id']==mun, value, mega_data['avg_floors_before_quake_municipal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVERAGE NUMBER OF FLOORS AFTER EARTHQUAKE  DISTRICT, MUNICIPAL and WARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#District LEvel\n",
    "mega_data['avg_floors_after_quake_district']=0\n",
    "for dist in district_list:\n",
    "        temp_new = pd.DataFrame()\n",
    "        temp_new = mega_data.loc[mega_data.district_id == dist, :]\n",
    "        temp_new = temp_new.reset_index()\n",
    "        temp_new.drop('index', axis=1, inplace=True)\n",
    "        \n",
    "        number_of_floors=temp_new['count_floors_post_eq'].sum()\n",
    "        value=number_of_floors/len(temp_new)\n",
    "        \n",
    "        mega_data['avg_floors_after_quake_district']=np.where(mega_data['district_id']==dist, value, mega_data['avg_floors_after_quake_district'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Municipal LEvel\n",
    "mega_data['avg_floors_after_quake_municipal']=0\n",
    "for mun in municipal_list:\n",
    "        temp_new = pd.DataFrame()\n",
    "        temp_new = mega_data.loc[mega_data.vdcmun_id == mun, :]\n",
    "        temp_new = temp_new.reset_index()\n",
    "        temp_new.drop('index', axis=1, inplace=True)\n",
    "        \n",
    "        number_of_floors=temp_new['count_floors_post_eq'].sum()\n",
    "        value=number_of_floors/len(temp_new)\n",
    "        \n",
    "        mega_data['avg_floors_after_quake_municipal']=np.where(mega_data['vdcmun_id']==mun, value, mega_data['avg_floors_after_quake_municipal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVERAGE NUMBER OF FAMILIES IN A DISTRICT & MUNICIPAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_data['avg_number_families_in_district']=0\n",
    "mega_data['number_of_families_in_district']=0\n",
    "for dist in district_list:\n",
    "    temp_new=pd.DataFrame()\n",
    "    temp_new=mega_data.loc[mega_data.district_id== dist,:]\n",
    "    temp_new=temp_new.reset_index()\n",
    "    temp_new.drop('index', axis=1, inplace=True)\n",
    "    \n",
    "    number_of_families=temp_new['count_families'].sum()\n",
    "    value=number_of_families/len(temp_new)\n",
    "    \n",
    "    mega_data['avg_number_families_in_district']=np.where(mega_data['district_id']==dist, value, mega_data['avg_number_families_in_district'])\n",
    "    mega_data['number_of_families_in_district']=np.where(mega_data['district_id']==dist, number_of_families, mega_data['number_of_families_in_district'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_data['avg_number_families_in_municipal']=0\n",
    "mega_data['number_of_families_in_municipal']=0\n",
    "for mun in municipal_list:\n",
    "    temp_new=pd.DataFrame()\n",
    "    temp_new=mega_data.loc[mega_data.vdcmun_id== mun,:]\n",
    "    temp_new=temp_new.reset_index()\n",
    "    temp_new.drop('index', axis=1, inplace=True)\n",
    "    \n",
    "    number_of_families=temp_new['count_families'].sum()\n",
    "    value=number_of_families/len(temp_new)\n",
    "    \n",
    "    mega_data['avg_number_families_in_municipal']=np.where(mega_data['vdcmun_id']==mun, value, mega_data['avg_number_families_in_municipal'])\n",
    "    mega_data['number_of_families_in_municipal']=np.where(mega_data['district_id']==dist, number_of_families, mega_data['number_of_families_in_municipal'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
